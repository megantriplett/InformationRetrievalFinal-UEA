{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d730d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mtmyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mtmyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mtmyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mtmyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\mtmyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\mtmyd\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports and downloads\n",
    "import nltk\n",
    "import spacy\n",
    "import json\n",
    "import math\n",
    "import glob\n",
    "import time\n",
    "import regex as re\n",
    "\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from spacy import displacy\n",
    "from nltk import pos_tag\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.distance import jaccard_distance \n",
    "from nltk.util import ngrams\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3810787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup\n",
    "stop_words  = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "040bd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads and returns the contents of a file\n",
    "#@param file_path the path name of the file\n",
    "#@returns contents_unfiltered unfiltered contents of the file\n",
    "def readFileContents (file_path):\n",
    "    with open(file_path) as file_object:\n",
    "        contents_unfiltered = file_object.read()\n",
    "    file_object.close()\n",
    "    return contents_unfiltered\n",
    "\n",
    "#Checks the spelling of a word not in corpus using the Jaccard Distance\n",
    "def spell_check(vocab, word):\n",
    "    correct_words = vocab\n",
    "    temp = [(jaccard_distance(set(ngrams(word, 2)), \n",
    "                              set(ngrams(w, 2))),w) \n",
    "            for w in correct_words if w[0]==word[0]] \n",
    "    return(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "\n",
    "#Uses Beautiful Soup to parse the contents of an html file\n",
    "#@param contents the contents to soupify\n",
    "#@title_weight1 the weight of content tagged heading1 \n",
    "#@title_weight2 the weight of content tagged heading2\n",
    "#@title_weight3 the weight of content tagged heading3\n",
    "#@title_weight4 the weight of content tagged title - usually wieghted highest\n",
    "#@returns string of content\n",
    "def soupify (contents, title_weight1 = 1, title_weight2 = 1, title_weight3 = 1, title_weight4 = 1):\n",
    "\n",
    "    #grabbing everything from the soup\n",
    "    soup = BeautifulSoup(contents, 'html.parser')\n",
    "    data = soup.find_all('p')\n",
    "    data.append(soup.find_all('span'))\n",
    "\n",
    "    #adds specified weighting to titles\n",
    "    for i in range(title_weight1):\n",
    "        data.append(soup.find_all('h1'))\n",
    "    for i in range(title_weight2):\n",
    "        data.append(soup.find_all('h2'))\n",
    "    for i in range(title_weight3):\n",
    "        data.append(soup.find_all('h3'))\n",
    "    for i in range(title_weight4):\n",
    "        data.append(soup.find_all('title'))\n",
    "        \n",
    "    data.append(soup.find_all('li'))\n",
    "\n",
    "    return str(data)\n",
    "\n",
    "#Performs lemmatization on non-tokenized contents\n",
    "#@param contents_not_tokenized contents that have not yet been tokenized\n",
    "#@returns string of contents      \n",
    "def lemmatize (contents_not_tokenized):\n",
    "    lemmed_string = ''\n",
    "    for w in contents_not_tokenized:\n",
    "        lemmed_string += '' + lemmatizer.lemmatize(w)\n",
    "    \n",
    "    return lemmed_string\n",
    "\n",
    "#Performs stemming on non-tokenized contents\n",
    "#@param contents_not_tokenized contents that have not yet been tokenized\n",
    "#@returns string of contents  \n",
    "def stemmatize (contents_not_tokenized):\n",
    "    stemmed_string = ''\n",
    "    for w in contents_not_tokenized:\n",
    "        stemmed_string += '' + ps.stem(w)\n",
    "        \n",
    "    return stemmed_string\n",
    "\n",
    "#Removes stop words from tokenized content\n",
    "#@param contents_tokenized the contents to remove stop words from\n",
    "#@returns list of tokenized strings with stop words removed\n",
    "def stopWords (contents_tokenized):\n",
    "    return [w for w in contents_tokenized if not w in stop_words]\n",
    "\n",
    "#Finds the high frequency bigrams from non-tokenized contents\n",
    "#High cost - requires tokenizing just to find freq dist of bigrams\n",
    "#Contents must be tokenized later too\n",
    "#@param contents_not_tokenized the non-tokenized contents\n",
    "#@param freq_requirement the amount of times a bigram must appear in a document to be included in the final lsit\n",
    "#@returns important_bigrams a dictionary with important bigrams as keys and their frequencies as values\n",
    "def bigrams (contents_not_tokenized, freq_requirement):\n",
    "    unfiltered_token = word_tokenize(contents_not_tokenized)\n",
    "    bigrams = nltk.bigrams(unfiltered_token)\n",
    "    frequency = nltk.FreqDist(bigrams)\n",
    "\n",
    "    important_bigrams = {}\n",
    "\n",
    "    for key, value in frequency.items():\n",
    "        if value > freq_requirement:\n",
    "            if not key[0] in stop_words and not key[1] in stop_words:  #or vs and here \n",
    "                important_bigrams[key[0] +\"_\" + key[1]] = value\n",
    "   \n",
    "    return important_bigrams\n",
    "        \n",
    "#Expands the query by producing a list of synonyms for any noun present\n",
    "#@param query tokenized version of query\n",
    "#@returns query_expansion list of synonyms for any noun in query\n",
    "def queryExpansion (query):\n",
    "    query_expansion = []\n",
    "    #expands the query\n",
    "    pos_tag(query)\n",
    "    nouns = [token for token, pos in pos_tag(query) if pos.startswith('N')]\n",
    "    for noun in nouns:\n",
    "        grouping = wordnet.synsets(noun)\n",
    "        for group in grouping:\n",
    "            lemmas = group.lemmas()\n",
    "            #can experiment with only appending top synonyms\n",
    "            for lemma in lemmas:\n",
    "                query_expansion.append(lemma.name())\n",
    "\n",
    "    return query_expansion\n",
    "            \n",
    "#Creates a list of Named Entities\n",
    "#@param contents string of contents - preferably after preprocessing to avoid numbers and punctuation\n",
    "#@returns named_entities list of Named Entities\n",
    "def namedEntityRecog (contents):\n",
    "    named_entities_list = []\n",
    "    processed = nlp(contents)\n",
    "    named_entities = processed.ents\n",
    "    for entity in named_entities:\n",
    "        named_entities_list.append(entity)\n",
    "    return named_entities_list\n",
    "\n",
    "#Removes HTMl tags, punctuation, and digits\n",
    "#Makes all letters lowercase\n",
    "#Allows words in query to easily match words in documents\n",
    "#@param contents_unfiltered non-tokenized contents that have not been filtered\n",
    "#@returns contents_not_tokenized string of filtered, non-tokenized contents\n",
    "def basicPreProcesssing (contents_unfiltered):\n",
    "    \n",
    "    #remove HTMl tags and newlines\n",
    "    contents_not_tokenized = re.sub(\"<.+?>|\\n\", \"\", contents_unfiltered)\n",
    "    #remove punctuation and digits\n",
    "    contents_not_tokenized = re.sub(\"[0-9]|[.?!,:;\\-(){}\\[\\]'\\\"â€”]\", \" \", contents_not_tokenized)  #Removing punctuation from text\n",
    "    #make all letters lowercase\n",
    "    contents_not_tokenized = contents_not_tokenized.lower()\n",
    "    \n",
    "    return contents_not_tokenized\n",
    "\n",
    "#Spacy tokenizes contents\n",
    "#@param contents_not_tokenized string of contents\n",
    "#@returns list of spacy tokens\n",
    "def tokenize (contents_not_tokenized):\n",
    "    tokens = word_tokenize(contents_not_tokenized)\n",
    "    return tokens\n",
    "\n",
    "#Saves the title of the html file and creates a description using tagged sections with query words present\n",
    "#Sections with more instances of the query words will appear first in the description\n",
    "#@param path the path of the file\n",
    "#@param query_words the tokenized list of the words in the query\n",
    "#@returns (title, final) tuple of \n",
    "    #title a string of the title \n",
    "    #final a list of tuples of strings of tagged sections and query word frequency \n",
    "def dynamicDescript(path, query_words):\n",
    "    # because path is object not string\n",
    "    path_in_str = str(path)\n",
    "\n",
    "    f = open(path, \"r\", encoding='utf-8')\n",
    "    contents = f.read()\n",
    "    f.close()\n",
    "\n",
    "    soup = BeautifulSoup(contents, 'html.parser')\n",
    "\n",
    "    title = str(soup.find_all('title'))\n",
    "\n",
    "    #removes the tags and brackets so that just the title of the video game is returned\n",
    "    title = re.sub(\"</*title>|\\n\", \"\", title)\n",
    "    title = re.sub(\"\\]\", \"\", title)\n",
    "    title = re.sub(\".+?:|\\n\", \"\", title)\n",
    "    \n",
    "\n",
    "    #prints the first two sentences of the document\n",
    "    description = str(soupify(contents))\n",
    "    description = re.sub(\"\\(([0-9]*/*)*\\)|\\n|\\b|\\t|\\s+-\\s+\", '', description)\n",
    "\n",
    "    #split on HTMl tags and newlines\n",
    "    description = re.split(\"<.+?>|\\n\", description)\n",
    "    final_description = {}\n",
    "    for item in description:\n",
    "        for word in query_words:\n",
    "            if word.lower() in item.lower():\n",
    "                if item not in final_description.keys():\n",
    "                    final_description[item] = 1\n",
    "                else:\n",
    "                    final_description[item] += 1\n",
    "\n",
    "    final = []\n",
    "    for item in final_description:\n",
    "        final.append((final_description[item], item))\n",
    "    final.sort(reverse=True)\n",
    "    \n",
    "\n",
    "    return (title, final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da81fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the documents according to the respective functions\n",
    "#while tokenizing, create a dictionary\n",
    "\n",
    "#https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory\n",
    "from pathlib import Path\n",
    "import glob\n",
    "directory_in_str = \"C:videogames\"\n",
    "pathList = []\n",
    "docIDs = {}\n",
    "i = 0\n",
    "tokens_full = []\n",
    "bigrams_list = []\n",
    "pathlist = Path(directory_in_str).glob('*.html')\n",
    "count = 0\n",
    "\n",
    "#initalizes the docIDs list and then tokenizes each webpage\n",
    "for path in pathlist:\n",
    "\n",
    "     # path is object not string\n",
    "    path_in_str = str(path)\n",
    "    pathList.append(path_in_str)\n",
    "\n",
    "    #creates docIDs list\n",
    "    docIDs[i] = path_in_str\n",
    "    i += 1\n",
    "\n",
    "    f = open(path_in_str, \"r\", encoding='utf-8')\n",
    "    contents_not_tokenized = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    #soupify contents to remove unnecessary text - such as font information\n",
    "    contents_not_tokenized = soupify(contents_not_tokenized, 5, 5, 5, 10)\n",
    "\n",
    "    #processes contents by making all letters lowercase and by removing punctuation and digits\n",
    "    contents_not_tokenized = basicPreProcesssing (contents_not_tokenized)\n",
    "\n",
    "    #creates a list of Named Entities from non-tokenized contents\n",
    "    #must make list before lemmatization or stemming in order to properly work\n",
    "    named_entities = namedEntityRecog(contents_not_tokenized) \n",
    "\n",
    "    #creates dictionary of bigrams as keys and respective frequencies as values\n",
    "    bigrams_list.append(bigrams(contents_not_tokenized, 5))\n",
    "\n",
    "    #choose lemmatization or stemming or none (not both - will cause chaos!)\n",
    "    # contents_not_tokenized = lemmatize (contents_not_tokenized)\n",
    "    # contents_not_tokenized = stemmatize (contents_not_tokenized)\n",
    "    \n",
    "    #tokenizes contents\n",
    "    contents_tokenized = tokenize (contents_not_tokenized)\n",
    "    \n",
    "    #removes stopwords from tokenized contents\n",
    "    contents_tokenized = stopWords (contents_tokenized)\n",
    "    \n",
    "    #add Named Entities to the end of contents_tokenized\n",
    "    #important to be placed after tokenization of regular contents to keep multi-word names together\n",
    "    #weights Named Entities higher\n",
    "    for item in named_entities:\n",
    "        contents_tokenized.append(str(item))\n",
    "    \n",
    "    vocab = []\n",
    "    update = []\n",
    "    #counts frequency of each term in contents_tokenized and appends to updates\n",
    "    for t in contents_tokenized:\n",
    "        if t not in vocab:\n",
    "            vocab.append(t)\n",
    "            update.append((t, contents_tokenized.count(t)))\n",
    "    \n",
    "    #list of lists of (tokens, count) in order of document\n",
    "    tokens_full.append(update)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0cb6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates postings list and vocabID list\n",
    "vocab = {}\n",
    "count = 0\n",
    "vocabID = 0\n",
    "postings = {}\n",
    "docIdCounter = 0\n",
    "length = []\n",
    "for doc in tokens_full:\n",
    "    length.append(0)\n",
    "    for (token, vocabCount) in doc:\n",
    "\n",
    "        #counts the number of terms in each document, to be used in cosine similarity\n",
    "        #does not count the length of the tf-idf of each term of the vector\n",
    "        #does not count bigrams or named entity recognition weightings\n",
    "        #does count different weightings of tokens in titles and headings\n",
    "        length[docIdCounter] += vocabCount*vocabCount\n",
    "        \n",
    "        if token not in vocab:\n",
    "            vocab[token] = count\n",
    "            vocabID = count\n",
    "            count += 1\n",
    "        else:\n",
    "            vocabID = vocab[token]\n",
    "        if vocabID in postings.keys():\n",
    "            postings[vocabID][docIdCounter] = vocabCount\n",
    "            \n",
    "        else:\n",
    "            postings[vocabID] = {docIdCounter : vocabCount}\n",
    "            \n",
    "    docIdCounter += 1\n",
    "\n",
    "#take the square root of every item in length list - relevant to cosine similarity\n",
    "for i in range (len(length)):\n",
    "    length[i] = math.sqrt(length[i] )\n",
    "\n",
    "#adds bigrams to postings list \n",
    "docIdCounter = 0\n",
    "for doc_bigrams in bigrams_list:\n",
    "    for key in doc_bigrams:\n",
    "        vocab[key] = count\n",
    "        vocabID = count\n",
    "        count += 1\n",
    "        postings[vocabID] = { docIdCounter : doc_bigrams[key]}\n",
    "    docIdCounter += 1\n",
    "    \n",
    "#creates txt files for vocab, postings, and docIDs lists for efficient storage and access\n",
    "with open('vocab.txt', 'w') as f: json.dump(vocab, f)\n",
    "with open('postings.txt', 'w') as f: json.dump(postings, f)\n",
    "with open('docids.txt', 'w') as f: json.dump(docIDs, f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af6dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a string of the top ten titles and respective descriptions based on final list\n",
    "#@param final the list of documents in order determined by tf-idf or cosine similarity\n",
    "#@param query_words the tokenized terms in the query\n",
    "def print_results_in_order(final, query_words):\n",
    "    \n",
    "    i = 0\n",
    "    result_in_string = ''\n",
    "    for (score, d) in final:\n",
    "        if i < 10:\n",
    "            (title, final_descript) = dynamicDescript(docIDs[str(d)], query_words)\n",
    "            # print(str(i+1) + ' ' + title)\n",
    "        \n",
    "            result_in_string += (str(i+1) + ' ' + title + '\\t')\n",
    "            result_in_string += (docIDs[str(d)] + '\\n')\n",
    "            \n",
    "            if len(final_descript) > 1:\n",
    "                # print('\\t' + final_descript[0][1] + '; ' , end=\"\")\n",
    "                result_in_string += ('\\t' + final_descript[0][1] + '; ')\n",
    "                if len(final_descript) > 2:\n",
    "                    # print(final_descript[1][1] + '; ' , end=\"\")\n",
    "                    # print(final_descript[2][1])\n",
    "                    result_in_string += (final_descript[1][1] + '; ' + final_descript[2][1]+ '\\n')\n",
    "                else:\n",
    "                    # print(final_descript[1][1])\n",
    "                    result_in_string += (final_descript[1][1]+ '\\n')\n",
    "            elif (len(final_descript) == 1):\n",
    "                # print(final_descript[0][1])\n",
    "                result_in_string += (final_descript[0][1] + '\\n' )\n",
    "            else:\n",
    "                break\n",
    "\n",
    "\n",
    "        i += 1\n",
    "    return(result_in_string)\n",
    "\n",
    "#prints the string from @function print_results_in_order and writes results to a file\n",
    "#@param final the list of documents in order determined by tf-idf or cosine similarity\n",
    "#@param query the string of the query input by the user\n",
    "#@param query_words the tokenized terms in the query\n",
    "def print_results_and_write_to_file(final, query, query_words, filename):\n",
    "    if final == []:\n",
    "        print('no results for this query')\n",
    "    else:\n",
    "        print(print_results_in_order(final, query_words))\n",
    "        with open(filename + '.txt', 'a') as f:  \n",
    "            f.write(query + '\\n')\n",
    "            f.write(print_results_in_order(final, query_words))         \n",
    "        f.close()\n",
    "\n",
    "#performs a cosine similarity analysis between the query and each document in the corpus\n",
    "#@param query_words the tokenized terms in the query\n",
    "#@param docIdCounter the number of documents in the corpus\n",
    "#@returns dot_product a list of tuples (cosine_similarity, documentID) sorted by cosine similarity score with the highest first\n",
    "def cosine_similarity(query_words, docIdCounter):\n",
    "\n",
    "    #setup\n",
    "    results = []\n",
    "    scores_dot = []\n",
    "    for i in range(docIdCounter):\n",
    "        scores_dot.append([])\n",
    "        scores_dot[i] = []\n",
    "    scores_query = []\n",
    "    query_length_count = 0\n",
    "\n",
    "    for word in query_words:\n",
    "        query_length_count += 1 \n",
    "        if word == \"quit\":\n",
    "            return ['quit']\n",
    "            break\n",
    "\n",
    "        if word in vocab:\n",
    "\n",
    "            termFreqTermQuery = 1 + math.log(query_words.count(word), 10)\n",
    "            scores_query.append(termFreqTermQuery)\n",
    "\n",
    "            vocabID = vocab[word]\n",
    "            i = 0\n",
    "\n",
    "            #calculate the tf for the query in each document in postings list\n",
    "            #don't have to calculate tf of non-query words bc we do the dot product with the query\n",
    "            for d in postings[str(vocabID)]:\n",
    "                \n",
    "                #TF-IDF\n",
    "                #1 plus the log of the frequency of the term in each document\n",
    "                #weighted\n",
    "                termFreqTermInDoc = 1 + math.log(postings[str(vocabID)][d], 10)\n",
    "                #dot product with query tf\n",
    "                scores_dot[int(d)].append(termFreqTermQuery*termFreqTermInDoc)\n",
    "    \n",
    "    dot_product = []\n",
    "    for i in range (len(scores_dot)):\n",
    "        total = 0\n",
    "        for score in scores_dot[i]:\n",
    "            if length[i] != 0:\n",
    "                total += score/(length[i]*query_length_count)\n",
    "        dot_product.append((total, i)) #total is the cosine similarity and i corresponds to the documentID\n",
    "    dot_product.sort(reverse=True)\n",
    "    return dot_product\n",
    "\n",
    "#performs a tf-idf analysis between the query and each document in the corpus\n",
    "#@param query_words the tokenized terms in the query\n",
    "#@param documentsInCorpus the amount of documents in the corpus\n",
    "#@returns final the list of tuples (tf-idf score, docID) sorted with highest tf-idf scores first\n",
    "def tf_idf(query_words, documentsInCorpus):\n",
    "    results = []\n",
    "\n",
    "        # retrieve documents that contain at least one of each term\n",
    "    for word in query_words:\n",
    "        if word == \"quit\":\n",
    "            return ['quit']\n",
    "            break\n",
    "\n",
    "        if word in vocab:\n",
    "            vocabID = vocab[word]\n",
    "            \n",
    "            corpusFreq = 0\n",
    "            \n",
    "            #count the number of documents in which this term occurs\n",
    "            for d in postings[str(vocabID)]:\n",
    "                corpusFreq += 1\n",
    "            \n",
    "            #if the word does not occur at all in the corpus\n",
    "            if corpusFreq == 0:\n",
    "                docFreqTerm = 0\n",
    "            \n",
    "            #if the word does occur in corpus, calculate its idf\n",
    "            else:\n",
    "                docFreqTerm = math.log(documentsInCorpus/corpusFreq, 10)\n",
    "                \n",
    "            #calculates the term frequency in each document\n",
    "            \n",
    "            #setup\n",
    "            output = {}\n",
    "            i = 0\n",
    "            \n",
    "            #the documents containing the word\n",
    "            for d in postings[str(vocabID)]:\n",
    "\n",
    "                  #TF-IDF\n",
    "                #1 plus the log of the frequency of the term in each document\n",
    "                #weighted\n",
    "                termFreqTerm = 1 + math.log(postings[str(vocabID)][d], 10)\n",
    "                \n",
    "                #unweighted\n",
    "#                 termFreqTerm = postings[str(vocabID)][d]\n",
    "                \n",
    "                #the product - the tf-idf\n",
    "                product = docFreqTerm*termFreqTerm\n",
    "                \n",
    "                #creates a dictionary with keys as document ids and values s tf-idf\n",
    "                output[d] = product\n",
    "                i+=1                  \n",
    "            \n",
    "            #appends to a list of outputs\n",
    "            results.append(output)\n",
    "            \n",
    "#         else:\n",
    "# #           query_words.append(spellcheck(word))\n",
    "\n",
    "    \n",
    "    #sums the tf-idf for each document for all words in query\n",
    "    second = {}\n",
    "    final = []\n",
    "\n",
    "    if len(results) == 0:\n",
    "        print(\"No results for this query\")\n",
    "        return []\n",
    "    elif len(results) == 1:\n",
    "        second = results[0]\n",
    "    else:\n",
    "        first = results[0]\n",
    "\n",
    "        for i in range(len(results)-1):\n",
    "            second = results[i+1]\n",
    "            for key1 in first:\n",
    "                for key2 in second:\n",
    "                    #if the key occurs in both dictionaries, update the second dictionary with the sum\n",
    "                    if key1 == key2:\n",
    "                        sum = first[key1] + second[key2]\n",
    "                        second[key2] = sum\n",
    "                    #if the key only occurs in the first dictionary, add it to the second\n",
    "                if key1 not in second:\n",
    "                    second[key1] = first[key1]\n",
    "            first = second\n",
    "\n",
    "    for doc in second:\n",
    "            final.append((second[doc], doc))\n",
    "\n",
    "    final.sort(reverse=True)  \n",
    "\n",
    "    return final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd9fed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You searched: Action-Adventure Games\n",
      "1  Streets of L.A.\tC:videogames\\true-crime-streets-of-la.html\n",
      "\tTrue Crime: Streets of L.A. , PS2, Action, Driving; A veteran developer of car-combat games prepares to release what you might call a GTA clone, but what Activision insists is a \"driving/fighting/shooting hybrid.\" Okay, cool, whatever! ; Action, Adventure\n",
      "2  X-Men Legends\tC:videogames\\x-men-legends.html\n",
      "\tGameSpy gets down and dirty with Activision's X-Men action-RPG. It features awesome multiplayer action and loads of little details that comic-book fans will love.; Play Games; Most Wanted Games of 2009\n",
      "3  Lockdown\tC:videogames\\rainbow-six-4-tentative-title.html\n",
      "\tWe go hands-on with the single and multiplayer action that you'll find in Ding Chavez's latest adventure.; The world's greatest counter-terrorism squad is back in action, and we got a chance to be the point man.; Play Games\n",
      "4  God of War\tC:videogames\\god-of-war.html\n",
      "\tWith some truly amazing combat and a dark, deep storyline, Sony's action game is destined to be a Greek classic.; SCEA reveals details on its upcoming action game set in ancient Greece. ; Great Hera! The gods of Olympus have blessed the PlayStation 2 with a truly divine action game. Slap on Hermes' sandals and pick it up now!\n",
      "5  Tom Clancy's Ghost Recon 2\tC:videogames\\tom-clancys-ghost-recon-2.html\n",
      "\tThis demonstration with voiceover show the sequel in action.; Watch the gameplay as designer Christian Allen discusses many technological upgrades for the game.; \");        }        // save old onloadvar ___oldWinOnload = window.onload;      // wait for the document.writeln to loadwindow.onload = function         {        // execute old one firstif (typeof(___oldWinOnload) == 'function') {___oldWinOnload;}        // tell them it's gamespy        NUCONOMY.ProjectToken = \"3e17decd-54\";            // log the PV; 1 = PV; 0 = value        NUCONOMY.Logger.LogActivity( getUsernameFromIgnLogin, '', document.location , 1, 0);            // the metadata will be the ATA name/value pairs        var tokens = ataxscript.split(\"'\");            tokens = tokens[1].split('/');            tokens[3] = tokens[3].split('?').join('&'); // add in query string             tokens[3] = tokens[3].split('&').join(';'); // convert to semi-colon delimited          // we need to use pagetype expressly        var tokens2 = tokens[3].split(';');        var pagetype = '';        try           {          for (token in tokens2)            {            if (tokens2[token].indexOf(\"pagetype\") == 0)              {              pagetype = tokens2[token].substring;  // remove pagetype=              break;              }            }          }        catch (err) {}          // set metadata---        NUCONOMY.Logger.SetContentMetadata (document.location, '' , pagetype, tokens[3] );        }      }    \n",
      "6  San Andreas\tC:videogames\\grand-theft-auto-san-andreas.html\n",
      "\tGame rentals of the week; Some small details about the backstory to Rockstar's popular action-driving game.; !  Take a look at the game in action!\n",
      "7  Devil May Cry 2\tC:videogames\\devil-may-cry-2.html\n",
      "\tPrepare for the next, stylish chapter of Capcom?s ultimate action thriller, Devil May Cry! Dante, the mysterious half-man, half-demon action hero is back to battle the legions of the underworld. Sporting trash-talking attitude and rock star good looks, Dante launches into a new adventure with twice the environments, twice the graphic sizzle and twice the gameplay of the original!; \");        }        // save old onloadvar ___oldWinOnload = window.onload;      // wait for the document.writeln to loadwindow.onload = function         {        // execute old one firstif (typeof(___oldWinOnload) == 'function') {___oldWinOnload;}        // tell them it's gamespy        NUCONOMY.ProjectToken = \"3e17decd-54\";            // log the PV; 1 = PV; 0 = value        NUCONOMY.Logger.LogActivity( getUsernameFromIgnLogin, '', document.location , 1, 0);            // the metadata will be the ATA name/value pairs        var tokens = ataxscript.split(\"'\");            tokens = tokens[1].split('/');            tokens[3] = tokens[3].split('?').join('&'); // add in query string             tokens[3] = tokens[3].split('&').join(';'); // convert to semi-colon delimited          // we need to use pagetype expressly        var tokens2 = tokens[3].split(';');        var pagetype = '';        try           {          for (token in tokens2)            {            if (tokens2[token].indexOf(\"pagetype\") == 0)              {              pagetype = tokens2[token].substring;  // remove pagetype=              break;              }            }          }        catch (err) {}          // set metadata---        NUCONOMY.Logger.SetContentMetadata (document.location, '' , pagetype, tokens[3] );        }      }    ; Play Games\n",
      "8  Tom Clancy's Splinter Cell Pandora Tomorrow\tC:videogames\\tom-clancys-splinter-cell-pandora-tomorrow.html\n",
      "\tUbisoft's stealth action game to infiltrate retail June 18th.; Ubisoft's stealth action game coming to both systems very soon.; Check out Sam Fisher's PS2 adventure in action!\n",
      "9  Resident Evil 4\tC:videogames\\resident-evil-4.html\n",
      "\tWe take the action XXL this week as Delsyn visits from the South office and chaos ensues!; The GameSpy Debriefings #8; Capcom's amazing horror action title creeps towards PS2, dragging juicy bonuses as it comes.\n",
      "10  Up Your Arsenal\tC:videogames\\ratchet-and-clank-up-your-arsenal.html\n",
      "\tPlay Games; Most Wanted Games of 2009; GameSpy: Ratchet &amp; Clank: Up Your Arsenal\n",
      "\n",
      "You searched: RPQ Games for Playstation\n",
      "1  Final Fantasy XII\tC:videogames\\final-fantasy-xii.html\n",
      "\tWe pay homage to the best games of the month. ; Company to show new Final Fantasy, Kingdom Hearts and Front Mission games.;  GameSpy Footage\n",
      "2  Monster Rancher EVO\tC:videogames\\monster-farm-5-circus-caravan.html\n",
      "\tTecmo's popular monster-breeding franchise heads to the circus, bringing along a new RPG element and deeper gameplay than fans of the series have ever seen before. ; Monsters leave the farm and run away with the circus in this role-playing game from Tecmo.; Play Games\n",
      "3  Shining Force EXA\tC:videogames\\shining-force-ikuse.html\n",
      "\tTrailer and gameplay footage included. ; Shining Force EXA debuts an innovative Fortress System by which players manage the growth, layout, and defense of the Geo Fortress, the player's home base. As players leave the Geo Fortress to go on missions and quests, they are kept abreast of events at the fortress, jumping back into characters from the home base as a defensive force if the fortress comes under attack. The Geo Fortress can evolve during the game to match players' personal style and tactics.; Play Games\n",
      "4  San Andreas\tC:videogames\\grand-theft-auto-san-andreas.html\n",
      "\tGame rentals of the week; We work hard to bring you the best video game information first. Check out the extra game coverage we have had.; We pay homage to the best games of the month.\n",
      "5  Resident Evil 4\tC:videogames\\resident-evil-4.html\n",
      "\tThe GameSpy Debriefings #8; Capcom brings one of the GameCube's crowning jewels to the PlayStation 2.;  GameSpy Footage\n",
      "6  Suikoden V\tC:videogames\\genso-suikoden-v.html\n",
      "\tPlay Games; Most Wanted Games of 2009; GameSpy: Suikoden V\n",
      "7  X-Men Legends\tC:videogames\\x-men-legends.html\n",
      "\tGameSpy gets down and dirty with Activision's X-Men action-RPG. It features awesome multiplayer action and loads of little details that comic-book fans will love.; Play Games; Most Wanted Games of 2009\n",
      "8  Devil May Cry 2\tC:videogames\\devil-may-cry-2.html\n",
      "\tPrepare for the next, stylish chapter of Capcom?s ultimate action thriller, Devil May Cry! Dante, the mysterious half-man, half-demon action hero is back to battle the legions of the underworld. Sporting trash-talking attitude and rock star good looks, Dante launches into a new adventure with twice the environments, twice the graphic sizzle and twice the gameplay of the original!; Play Games; Most Wanted Games of 2009\n",
      "9  Persona 3 FES\tC:videogames\\persona-3-fes-.html\n",
      "\tThe GameSpy Debriefings #44; The GameSpy Debriefings #43; The GameSpy Debriefing #11\n",
      "10  Journey of the Cursed King\tC:videogames\\dragon-warrior-viii.html\n",
      "\tThe originator of the console RPG sticks to its roots while rapidly evolving into a game that will come to define the PlayStation 2 experience. ; We pay homage to the best games of the month.; Play Games\n",
      "\n",
      "You searched: The Guy Game\n",
      "1  Family Guy\tC:videogames\\family-guy.html\n",
      "\tFamily Guy; GameSpy: Family Guy; Shenanigans from the upcoming videogame.\n",
      "2  The Guy Game\tC:videogames\\the-guy-game.html\n",
      "\tThe Guy Game; The Guy Game (PS2); GameSpy: The Guy Game\n",
      "3  Rogue Agent\tC:videogames\\james-bond-007-goldeneye-2.html\n",
      "\tHad your fill of the hero thing? EA's latest Bond game turns the tables and lets you be the guy giving monologues.;  is back, at least in name, and it looks like the most interesting Bond game in years.; While it might not be as groundbreaking as its predecessor, this game has what it takes keep gamers entertained for a long time.\n",
      "4  Evil Dead Regeneration\tC:videogames\\evil-dead-regeneration.html\n",
      "\tPlay Games; Most Wanted Games of 2009; GameSpy: Evil Dead Regeneration\n",
      "5  Deception\tC:videogames\\mortal-kombat-deception.html\n",
      "\tVideo Game Awards 2004 Award Winners Announced; Various modes are shown off in this gameplay footage. Fatality!; Play Games\n",
      "6  Kelly Slater's Pro Surfer\tC:videogames\\kelly-slaters-pro-surfer.html\n",
      "\tPlay Games; Most Wanted Games of 2009; GameSpy: Kelly Slater's Pro Surfer\n",
      "7  Final Fantasy VII\tC:videogames\\final-fantasy-vii-2006.html\n",
      "\tBlockbuster Video Top 10 Videogame Rentals; The most popular game in the history of the ; Play Games\n",
      "8  Aqua Teen Hunger Force Zombie Ninja Pro-Am\tC:videogames\\aqua-teen-hunger-force-zombie-ninja-pro-am.html\n",
      "\tDo battle against Carl, the Mooninites, MC Pee Pants, the Plutonians and other classic villains. Drive your electric golf cart like a real jerk, with complete disregard for your own life. Race against theFrat Aliens in a deadly game of cat and mouse. Hear the actual voices of your favorite cartoon characters,recorded in incredible digital quality. Learn how to finally hit a sand wedge properly. Onlyyou can ensure that Master Shake is triumphant over evil, and the mandatory dress code regarding collared shirts.; \");        }        // save old onloadvar ___oldWinOnload = window.onload;      // wait for the document.writeln to loadwindow.onload = function         {        // execute old one firstif (typeof(___oldWinOnload) == 'function') {___oldWinOnload;}        // tell them it's gamespy        NUCONOMY.ProjectToken = \"3e17decd-54\";            // log the PV; 1 = PV; 0 = value        NUCONOMY.Logger.LogActivity( getUsernameFromIgnLogin, '', document.location , 1, 0);            // the metadata will be the ATA name/value pairs        var tokens = ataxscript.split(\"'\");            tokens = tokens[1].split('/');            tokens[3] = tokens[3].split('?').join('&'); // add in query string             tokens[3] = tokens[3].split('&').join(';'); // convert to semi-colon delimited          // we need to use pagetype expressly        var tokens2 = tokens[3].split(';');        var pagetype = '';        try           {          for (token in tokens2)            {            if (tokens2[token].indexOf(\"pagetype\") == 0)              {              pagetype = tokens2[token].substring;  // remove pagetype=              break;              }            }          }        catch (err) {}          // set metadata---        NUCONOMY.Logger.SetContentMetadata (document.location, '' , pagetype, tokens[3] );        }      }    ; Play Games\n",
      "9  Finest Hour\tC:videogames\\call-of-duty-finest-hour.html\n",
      "\tActivision's gritty, realistic shooter is shaping up to be one of the finest WWII games ever to hit your console.; Video Game Awards 2004 Award Winners Announced; The PC game that everyone is talking about is finally coming to a console near you.\n",
      "10  Streets of L.A.\tC:videogames\\true-crime-streets-of-la.html\n",
      "\tA veteran developer of car-combat games prepares to release what you might call a GTA clone, but what Activision insists is a \"driving/fighting/shooting hybrid.\" Okay, cool, whatever! ; \");        }        // save old onloadvar ___oldWinOnload = window.onload;      // wait for the document.writeln to loadwindow.onload = function         {        // execute old one firstif (typeof(___oldWinOnload) == 'function') {___oldWinOnload;}        // tell them it's gamespy        NUCONOMY.ProjectToken = \"3e17decd-54\";            // log the PV; 1 = PV; 0 = value        NUCONOMY.Logger.LogActivity( getUsernameFromIgnLogin, '', document.location , 1, 0);            // the metadata will be the ATA name/value pairs        var tokens = ataxscript.split(\"'\");            tokens = tokens[1].split('/');            tokens[3] = tokens[3].split('?').join('&'); // add in query string             tokens[3] = tokens[3].split('&').join(';'); // convert to semi-colon delimited          // we need to use pagetype expressly        var tokens2 = tokens[3].split(';');        var pagetype = '';        try           {          for (token in tokens2)            {            if (tokens2[token].indexOf(\"pagetype\") == 0)              {              pagetype = tokens2[token].substring;  // remove pagetype=              break;              }            }          }        catch (err) {}          // set metadata---        NUCONOMY.Logger.SetContentMetadata (document.location, '' , pagetype, tokens[3] );        }      }    ; Play Games\n",
      "\n",
      "You searched: Spyder-Man\n",
      "1  Spider-Man 3\tC:videogames\\spider-man-3.html\n",
      "\tSpider-Man 3; Spider-Man 3 Strategy Guide; Spider-Man 3 (PS2)\n",
      "2  Friend or Foe\tC:videogames\\spider-man-trilogy.html\n",
      "\tSpider-Man: Friend or Foe (PS2); Spider-Man: Friend or Foe; GameSpy: Spider-Man: Friend or Foe\n",
      "3  Pac-Man World Rally\tC:videogames\\pac-man-world-rally.html\n",
      "\tPac-Man World Rally; Pac-Man World Rally Trailer; Pac-Man World Rally Retro Maze Video\n",
      "4  Iron Man\tC:videogames\\iron-man-2008.html\n",
      "\tIron Man; Get to know Iron Man's greatest weapons including unlockable and platform-exclusive suits.; Iron Man Guide\n",
      "5  Mega Man X Collection\tC:videogames\\mega-man-x-collection.html\n",
      "\tMega Man X Collection; Relive Mega Man's gritty future with this compilation of classic games (with a dud or two tossed in for good measure).; Mega Man's future may look bleak, but the games based on that future look better than ever.\n",
      "6  Mega Man X8\tC:videogames\\mega-man-x8.html\n",
      "\tMega Man X8; Mega Man X8 (PS2); Mega Man Collection\n",
      "7  2econd Coming\tC:videogames\\shadow-man-2econd-coming.html\n",
      "\tShadow Man: 2econd Coming Prima Guide; Shadow Man: 2econd Coming (PS2); GameSpy: Shadow Man: 2econd Coming\n",
      "8  Ultimate Alliance\tC:videogames\\untitled-marvel-comics-rpg.html\n",
      "\tSpiderman, Thor, and The Thing video profiles.; Assume the roles of more than 20 Marvel Super Heroes including Spider-Man, Wolverine, Blade and Captain America and help save planet Earth.\n",
      "9  Wolverine's Revenge\tC:videogames\\x2-wolverines-revenge.html\n",
      "\tThe hirsute, ill-tempered, and squat X-Man sets out on an all-new, all-different adventure.; The overly hairy Wolverine gives gamers an adamantium one-fingered salute.\n",
      "10  50th Anniversary\tC:videogames\\namco-museum-50th-anniversary-arcade-collection.html\n",
      "Pac-Man, Ms. Pac-Man, Galaga, Galaxian, Dig Dug, Pole Position, Pole Position II, Rolling Thunder, Rally X, Bosconian, Dragon Spirit, Sky Kid, Xevious\n",
      "\n",
      "You searched: star-wars-battlefront\n",
      "1  Star Wars Battlefront\tC:videogames\\star-wars-battlefront.html\n",
      "\tStar Wars Battlefront; Star Wars: Battlefront; Star Wars\n",
      "2  The Video Game\tC:videogames\\lego-star-wars.html\n",
      "\tLEGO Star Wars; Star Wars; LEGO Star Wars: The Video Game\n",
      "3  The Original Trilogy\tC:videogames\\lego-star-wars-the-original-trilogy.html\n",
      "\tLEGO Star Wars II: The Original Trilogy; Legos + Original Star Wars = Fun; Lego Star Wars II Trailer\n",
      "4  Phantasy Star Universe\tC:videogames\\phantasy-star-universe.html\n",
      "\tPhantasy Star Universe; Phantasy Star; Phantasy Star Universe.\n",
      "5  Revenge of the Sith\tC:videogames\\star-wars-episode-iii.html\n",
      "\tStar Wars: Episode III; Star Wars Episode III: Revenge of the Sith; Star Wars Episode III: Revenge of the Sith Strategy Guide\n",
      "6  Ambition of the Illuminus\tC:videogames\\phantasy-star-universe-ambition-of-illuminus.html\n",
      "\tPhantasy Star Universe...; Phantasy Star Universe; Phantasy Star Universe: Ambition of the Illuminus\n",
      "7  Mercenaries\tC:videogames\\mercenaries.html\n",
      "\tLucasArts' lone upcoming non-Star Wars title is shaping up to be a jewel in the company's crown.; This atypical war game gives you ; LucasArts and Pandemic team up again to bring you a war you might not expect.\n",
      "8  NARC\tC:videogames\\narc.html\n",
      "\tMidway's shooter gets star powered cast.; Third-person shooter of the elite NARC squad in the war on drugs.; E3 Annual Awards\n",
      "9  NBA Live 2005\tC:videogames\\nba-live-2005.html\n",
      "\tTake a look at all of the new additions to the 5-on-5 game, as well as the hot All-Star Weekend action!; Gamers don't have to take the All-Star weekend off this year, thanks to some amazing new additions.; See the Warriors' Jason Richardson in action ...\n",
      "10  The Unsung War\tC:videogames\\ace-combat-5-the-unsung-war.html\n",
      "\tAce Combat 5: The Unsung War; GameSpy: Ace Combat 5: The Unsung War; Cheats for Ace Combat 5: The Unsung War\n",
      "\n",
      "You searched: Iron Man\n",
      "1  Iron Man\tC:videogames\\iron-man-2008.html\n",
      "\tIron Man; Get to know Iron Man's greatest weapons including unlockable and platform-exclusive suits.; Drawing from both the movie and comic book storylines, Iron Man features the voice talent of the stars from the major motion picture -- Robert Downey Jr, Terrence Howard, and Shawn Toub. Large exterior environments and dark indoor areas can be fully explored and systematically ripped apart for an authentic and explosive cinematic experience.\n",
      "2  Pac-Man World Rally\tC:videogames\\pac-man-world-rally.html\n",
      "\tPac-Man World Rally; Pac-Man World Rally Trailer; Pac-Man World Rally Retro Maze Video\n",
      "3  Mega Man X Collection\tC:videogames\\mega-man-x-collection.html\n",
      "\tMega Man X Collection; Relive Mega Man's gritty future with this compilation of classic games (with a dud or two tossed in for good measure).; Mega Man's future may look bleak, but the games based on that future look better than ever.\n",
      "4  Mega Man X8\tC:videogames\\mega-man-x8.html\n",
      "\tMega Man X8; Mega Man X8 (PS2); Mega Man Collection\n",
      "5  Spider-Man 3\tC:videogames\\spider-man-3.html\n",
      "\tSpider-Man 3; Spider-Man 3 Strategy Guide; Spider-Man 3 (PS2)\n",
      "6  Friend or Foe\tC:videogames\\spider-man-trilogy.html\n",
      "\tSpider-Man: Friend or Foe (PS2); Spider-Man: Friend or Foe; GameSpy: Spider-Man: Friend or Foe\n",
      "7  2econd Coming\tC:videogames\\shadow-man-2econd-coming.html\n",
      "\tShadow Man: 2econd Coming Prima Guide; Shadow Man: 2econd Coming (PS2); GameSpy: Shadow Man: 2econd Coming\n",
      "8  Wolverine's Revenge\tC:videogames\\x2-wolverines-revenge.html\n",
      "\tThe hirsute, ill-tempered, and squat X-Man sets out on an all-new, all-different adventure.; The overly hairy Wolverine gives gamers an adamantium one-fingered salute.; Features\n",
      "9  50th Anniversary\tC:videogames\\namco-museum-50th-anniversary-arcade-collection.html\n",
      "\tPac-Man, Ms. Pac-Man, Galaga, Galaxian, Dig Dug, Pole Position, Pole Position II, Rolling Thunder, Rally X, Bosconian, Dragon Spirit, Sky Kid, Xevious; if((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"; function pr_swfver{var osf,osfd,i,axo=1,v=0,nv=navigator;if(nv.plugins&&nv.mimeTypes.length){osf=nv.plugins[\"Shockwave Flash\"];if(osf&&osf.description){osfd=osf.description;v=parseInt(osfd.substring(osfd.indexOf(\".\")-2))}}else{try{for(i=5;axo!=null;i++){axo=new ActiveXObject(\"ShockwaveFlash.ShockwaveFlash.\"+i);v=i}}catch(e){}}return v;}var pr_d=new Date;pr_d=pr_d.getDay+\"|\"+pr_d.getHours+\":\"+pr_d.getMinutes+\"|\"+-pr_d.getTimezoneOffset/60;var pr_redir=\"$CTURL$\";var pr_nua=navigator.userAgent.toLowerCase;var pr_pos=\"\",pr_inif=(window!=top);if(pr_inif){try{pr_pos=(typeof(parent.document)!=\"unknown\")?(((typeof(inDapIF)!=\"undefined\")&&(inDapIF))||(parent.document.domain==document.domain))?\"&pos=s\":\"&pos=x\":\"&pos=x\";}catch(e){pr_pos=\"&pos=x\";}if(pr_pos==\"&pos=x\"){var pr_u=new RegExp(\"[A-Za-z]+:[/][/][A-Za-z0-9.-]+\");var pr_t=this.window.document.referrer;var pr_m=pr_t.match(pr_u);if(pr_m!=null){pr_pos+=\"&dom=\"+pr_m[0];}}else{if(((typeof(inDapMgrIf)!=\"undefined\")&&(inDapMgrIf))||((typeof(isAJAX)!=\"undefined\")&&(isAJAX))){pr_pos+=\"&ajx=1\"}}}var pr_s=\"ads.pointroll.com/PortalServe/?pid=710500I49220081223214526&flash=\"+pr_swfver+\"&time=\"+pr_d+\"&redir=\"+pr_redir+pr_pos+\"&r=\"+Math.random;document.write(\"\n",
      "10  Rogue Agent\tC:videogames\\james-bond-007-goldeneye-2.html\n",
      "\tWe get a hands-on with the baddest man that ever roamed the 007 universe.; Why play a good guy when you can rule the world? EA tells you why bad is good.; Features\n",
      "\n",
      "You searched: James Earl Cash\n",
      "1  Fight for NY\tC:videogames\\def-jam-vendetta-2.html\n",
      "\tDef Jam: Fight for NY; Def Jam Vendetta II; Def Jam FIGHT for NY\n",
      "2  Def Jam Vendetta\tC:videogames\\def-jam-vendetta.html\n",
      "\tDef Jam Vendetta ; Def Jam FIGHT for NY; Def Jam FIGHT For NY\n",
      "3  Rock Band (Special Edition)\tC:videogames\\rock-band-special-edition.html\n",
      "As part of our Game of the Year interview series, we jam with the VP of development for \n",
      "4  Legends of Rock\tC:videogames\\guitar-hero-iii.html\n",
      "\tPlayers convene in NYC for a record-breaking jam session to mark the launch of Guinness World Records: Gamer's Edition 2008.; The latest shredfest is a solid title, but the PS2 version clearly got the short end of this stick this go-round. \n",
      "5  Manhunt\tC:videogames\\manhunt.html\n",
      "The team that brought us GTA3 and Vice City takes mature gaming to the next level. Take on the role of James Earl Cash in a sick game of kill-or-be-killed. Bring on the Manhunt! \n",
      "6  The Hollywood Quiz\tC:videogames\\buzz-the-hollywood-quiz.html\n",
      "\tPS2 Brings the Party into Your Living Room with Buzz! the Hollywood Quiz and Buzz! Jr.: Robo Jam; , Buzz! Jr. RoboJam and Buzz! PSP\n",
      "7  Mercenaries\tC:videogames\\mercenaries.html\n",
      "Forget working at McD's. Earn cash the old fashioned way: killing people.\n",
      "8  WWE Crush Hour\tC:videogames\\wwe-crush-hour.html\n",
      "\tWWE: Crush Hour ; WWE Crush Hour (PS2); GameSpy: WWE Crush Hour\n",
      "9  Duel Masters\tC:videogames\\duel-masters.html\n",
      "The new card on the block has the potential to make you say, \"Yu Gi Who?\"\n",
      "10  Street Racing Syndicate\tC:videogames\\street-racing-syndicate.html\n",
      "Take a spin in the latest street racer in the block.\n",
      "\n",
      "You searched: Crazy Taxi\n",
      "1  Crazy Taxi\tC:videogames\\crazy-taxi.html\n",
      "\tGameSpy: Crazy Taxi; Crazy Taxi Strategy Guide; Crazy Taxi (PS2)\n",
      "2  The King of Route 66\tC:videogames\\the-king-of-route-66.html\n",
      "Crazy Taxi meets big rigs in a goofy, mildly racist, short-lived arcade racer.\n",
      "3  Crazy Frog Racer\tC:videogames\\crazy-frog-racer.html\n",
      "\tif((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"; Crazy Frog Racer; Crazy Frog Racer Cheats\n",
      "4  Redemption\tC:videogames\\hackgu-part-3.html\n",
      "\tif((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"; .hack//G.U. Vol.3: Red...; Cheats for .hack//G.U. Vol.3: Redemption\n",
      "5  Rebirth\tC:videogames\\hackgu.html\n",
      "\t.hack//G.U.; if((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"; .hack//G.U. Vol. 1: Re...\n",
      "6  Endgame\tC:videogames\\endgame.html\n",
      "if((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"\n",
      "7  Guilty Gear X\tC:videogames\\guilty-gear-x.html\n",
      "if((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"\n",
      "8  Dante's Awakening\tC:videogames\\devil-may-cry-3.html\n",
      "if((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"\n",
      "9  Buzz! The Mega Quiz\tC:videogames\\buzz-the-mega-quiz.html\n",
      "if((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"\n",
      "10  Also Sprach Zarathustra\tC:videogames\\xenosaga-iii.html\n",
      "if((typeof ataxscript == 'undefined' || ataxscript.length == 0) &&   (typeof ataximg == 'undefined' || ataximg.length == 0) &&   (typeof showStitial == 'undefined' || !showStitial) &&   (typeof forwardedByStitial == 'undefined' || !forwardedByStitial)){    var now  = new Date;    var random  = now.getTime;    var ref  = (document.referrer)?'&r='+escape(document.referrer):'';        ref      = ref.split('/').join('%2F');        ref      = ref.split('.').join('%2E');        ref      = ref.split('%').join('$');    var ataxscript = \"\n",
      "\n",
      "You searched: James Bond\n",
      "1  NightFire\tC:videogames\\james-bond-007-nightfire.html\n",
      "\tJames Bond 007: NightFire Strategy Guide; James Bond 007: NightFire (PS2); GameSpy: James Bond 007: NightFire\n",
      "2  Rogue Agent\tC:videogames\\james-bond-007-goldeneye-2.html\n",
      "\tEnter the world of superagent James Bond, but from the other side. It's fun to be bad!; Had your fill of the hero thing? EA's latest Bond game turns the tables and lets you be the guy giving monologues.; EA's latest Bond shooter invites you to be the bad guy, but it turns out evil isn't as rewarding as you might have thought.\n",
      "3  Fight for NY\tC:videogames\\def-jam-vendetta-2.html\n",
      "\tDef Jam: Fight for NY; Def Jam Vendetta II; Def Jam FIGHT for NY\n",
      "4  Def Jam Vendetta\tC:videogames\\def-jam-vendetta.html\n",
      "\tDef Jam Vendetta ; Def Jam FIGHT for NY; Def Jam FIGHT For NY\n",
      "5  Legends of Rock\tC:videogames\\guitar-hero-iii.html\n",
      "\tPlayers convene in NYC for a record-breaking jam session to mark the launch of Guinness World Records: Gamer's Edition 2008.; The latest shredfest is a solid title, but the PS2 version clearly got the short end of this stick this go-round. \n",
      "6  Rock Band (Special Edition)\tC:videogames\\rock-band-special-edition.html\n",
      "\tAs part of our Game of the Year interview series, we jam with the VP of development for ; The Rock Band: Special Edition Bundle for the PlayStation 2 system features a wireless Fender Stratocaster guitar controller, an electronic drum kit, real drum sticks, a microphone and software -- it's everything you need to get in the game and rock out!\n",
      "7  The Hollywood Quiz\tC:videogames\\buzz-the-hollywood-quiz.html\n",
      "\tPS2 Brings the Party into Your Living Room with Buzz! the Hollywood Quiz and Buzz! Jr.: Robo Jam; , Buzz! Jr. RoboJam and Buzz! PSP\n",
      "8  WWE Crush Hour\tC:videogames\\wwe-crush-hour.html\n",
      "\tWWE: Crush Hour ; WWE Crush Hour (PS2); GameSpy: WWE Crush Hour\n",
      "9  Ultimate Alliance\tC:videogames\\untitled-marvel-comics-rpg.html\n",
      "\tMarvel: Ultimate Alliance; Marvel: Ultimate Alliance Trailer; Sue Storm makes an appearance in the latest Marvel: Ultimate Alliance video.\n",
      "10  Duel Masters\tC:videogames\\duel-masters.html\n",
      "The new card on the block has the potential to make you say, \"Yu Gi Who?\"\n",
      "\n",
      "You searched: The Lord of the Rings: The Two Towers\n",
      "1  Fight Night Round 3\tC:videogames\\ea-sports-fight-night-round-3.html\n",
      "\tWe step into the virtual ring to take a look at the latest entry in EA's popular boxing series.; Around the Network; Planet Call of Duty\n",
      "2  The Two Towers\tC:videogames\\the-lord-of-the-rings-the-two-towers.html\n",
      "\tThe Lord of the Rings: The Two Towers Strategy Guide; The Lord of the Rings: The Two Towers (PS2); The Lord of the Rings: The Two Towers\n",
      "3  Rock Band (Special Edition)\tC:videogames\\rock-band-special-edition.html\n",
      "\tRock Band; \");        }        // save old onloadvar ___oldWinOnload = window.onload;      // wait for the document.writeln to loadwindow.onload = function         {        // execute old one firstif (typeof(___oldWinOnload) == 'function') {___oldWinOnload;}        // tell them it's gamespy        NUCONOMY.ProjectToken = \"3e17decd-54\";            // log the PV; 1 = PV; 0 = value        NUCONOMY.Logger.LogActivity( getUsernameFromIgnLogin, '', document.location , 1, 0);            // the metadata will be the ATA name/value pairs        var tokens = ataxscript.split(\"'\");            tokens = tokens[1].split('/');            tokens[3] = tokens[3].split('?').join('&'); // add in query string             tokens[3] = tokens[3].split('&').join(';'); // convert to semi-colon delimited          // we need to use pagetype expressly        var tokens2 = tokens[3].split(';');        var pagetype = '';        try           {          for (token in tokens2)            {            if (tokens2[token].indexOf(\"pagetype\") == 0)              {              pagetype = tokens2[token].substring;  // remove pagetype=              break;              }            }          }        catch (err) {}          // set metadata---        NUCONOMY.Logger.SetContentMetadata (document.location, '' , pagetype, tokens[3] );        }      }    ; Rock Band (Special Edi...\n",
      "4  Band of Thieves\tC:videogames\\sly-2-band-of-thieves.html\n",
      "\tSly 2: Band of Thieves; Sly 2: Band of Thieves Strategy Guide; Sly 2: Band of Thieves (PS2)\n",
      "5  Baroque\tC:videogames\\baroque.html\n",
      "\tEnter the dreaded Neuro Tower in search of absolution.; Around the Network; Planet Call of Duty\n",
      "6  Guitar Hero II\tC:videogames\\guitar-hero-2.html\n",
      "\tHere's what E3 attendees will get a taste of during the show.; Primus' Les Claypool discusses how his band's \"John The Fisherman\" wound up in ; Get Your Band Into \n",
      "7  Final Fantasy VII\tC:videogames\\final-fantasy-vii-2006.html\n",
      "\t spinoff, the dirge tolls for thee.; Around the Network; Planet Call of Duty\n",
      "8  Legends of Rock\tC:videogames\\guitar-hero-iii.html\n",
      "\tThe highest scoring rockers win an all-expense paid trip to California for a tour of Neversoft's studio.; RedOctane reveals first details on its latest offering.; function pr_swfver{var osf,osfd,i,axo=1,v=0,nv=navigator;if(nv.plugins&&nv.mimeTypes.length){osf=nv.plugins[\"Shockwave Flash\"];if(osf&&osf.description){osfd=osf.description;v=parseInt(osfd.substring(osfd.indexOf(\".\")-2))}}else{try{for(i=5;axo!=null;i++){axo=new ActiveXObject(\"ShockwaveFlash.ShockwaveFlash.\"+i);v=i}}catch(e){}}return v;}var pr_d=new Date;pr_d=pr_d.getDay+\"|\"+pr_d.getHours+\":\"+pr_d.getMinutes+\"|\"+-pr_d.getTimezoneOffset/60;var pr_redir=\"$CTURL$\";var pr_nua=navigator.userAgent.toLowerCase;var pr_pos=\"\",pr_inif=(window!=top);if(pr_inif){try{pr_pos=(typeof(parent.document)!=\"unknown\")?(((typeof(inDapIF)!=\"undefined\")&&(inDapIF))||(parent.document.domain==document.domain))?\"&pos=s\":\"&pos=x\":\"&pos=x\";}catch(e){pr_pos=\"&pos=x\";}if(pr_pos==\"&pos=x\"){var pr_u=new RegExp(\"[A-Za-z]+:[/][/][A-Za-z0-9.-]+\");var pr_t=this.window.document.referrer;var pr_m=pr_t.match(pr_u);if(pr_m!=null){pr_pos+=\"&dom=\"+pr_m[0];}}else{if(((typeof(inDapMgrIf)!=\"undefined\")&&(inDapMgrIf))||((typeof(isAJAX)!=\"undefined\")&&(isAJAX))){pr_pos+=\"&ajx=1\"}}}var pr_s=\"ads.pointroll.com/PortalServe/?pid=710500I49220081223214526&flash=\"+pr_swfver+\"&time=\"+pr_d+\"&redir=\"+pr_redir+pr_pos+\"&r=\"+Math.random;document.write(\"\n",
      "9  Honor Among Thieves\tC:videogames\\sly-3.html\n",
      "\tLock up your valuables! Sucker Punch is bringing its band of thieves back for another heist.; Games starring Navy SEALs, giants, and furry animals hit $19.99; Around the Network\n",
      "10  Persona 3 FES\tC:videogames\\persona-3-fes-.html\n",
      "\t\");        }        // save old onloadvar ___oldWinOnload = window.onload;      // wait for the document.writeln to loadwindow.onload = function         {        // execute old one firstif (typeof(___oldWinOnload) == 'function') {___oldWinOnload;}        // tell them it's gamespy        NUCONOMY.ProjectToken = \"3e17decd-54\";            // log the PV; 1 = PV; 0 = value        NUCONOMY.Logger.LogActivity( getUsernameFromIgnLogin, '', document.location , 1, 0);            // the metadata will be the ATA name/value pairs        var tokens = ataxscript.split(\"'\");            tokens = tokens[1].split('/');            tokens[3] = tokens[3].split('?').join('&'); // add in query string             tokens[3] = tokens[3].split('&').join(';'); // convert to semi-colon delimited          // we need to use pagetype expressly        var tokens2 = tokens[3].split(';');        var pagetype = '';        try           {          for (token in tokens2)            {            if (tokens2[token].indexOf(\"pagetype\") == 0)              {              pagetype = tokens2[token].substring;  // remove pagetype=              break;              }            }          }        catch (err) {}          // set metadata---        NUCONOMY.Logger.SetContentMetadata (document.location, '' , pagetype, tokens[3] );        }      }    ; Rock Band; Around the Network\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('vocab.txt', 'r') as f: vocab = json.load(f)\n",
    "with open('postings.txt', 'r') as f: postings = json.load(f)\n",
    "with open('docids.txt', 'r') as f: docIDs = json.load(f)\n",
    "filename = 'results'\n",
    "while True:\n",
    "    query = input(\"What would you like to query?\")\n",
    "    if query == 'quit':\n",
    "        break\n",
    "    print(\"You searched: \" + query)\n",
    "    query_words = basicPreProcesssing(query)\n",
    "\n",
    "    # named_entities = namedEntityRecog(query_words) \n",
    "    # print(named_entities)\n",
    "\n",
    "    # query_words = stemmatize(query_words)\n",
    "    query_words = lemmatize(query_words)\n",
    "\n",
    "    query_words = word_tokenize(query_words)\n",
    "\n",
    "    #spell_check\n",
    "    for word in query_words:\n",
    "        if word not in vocab and word != None:\n",
    "            \n",
    "            if spell_check(vocab,word) != None:\n",
    "                index = query_words.index(word)\n",
    "                query_words.remove(word)\n",
    "                query_words.insert(index, tokenize(spell_check(vocab,word))[0])\n",
    "\n",
    "    \n",
    "    #query expansion using synonyms for nouns\n",
    "    #will increase the length of the query during cosine similarity\n",
    "    query_expansion = queryExpansion(query_words)\n",
    "    query_words += query_expansion\n",
    "\n",
    "    #add bigrams to query\n",
    "    query_bigrams = bigrams(query, 0)\n",
    "    # query_words += query_bigrams\n",
    "    \n",
    "    # # # #add named entities to query_words\n",
    "    # for item in named_entities:\n",
    "    #     query_words.append(str(item))\n",
    "\n",
    "    documentsInCorpus = len(docIDs)\n",
    "\n",
    "    #choose one\n",
    "    final = tf_idf(query_words, documentsInCorpus)\n",
    "    if final ==  ['quit']:\n",
    "        print('quitting')\n",
    "        break\n",
    "\n",
    "    print_results_and_write_to_file(final, query, query_words, filename)\n",
    "\n",
    "    # final = cosine_similarity(query_words, documentsInCorpus)\n",
    "    # if final ==  ['quit']:\n",
    "    #     print('quitting')\n",
    "    #     break\n",
    "\n",
    "\n",
    "    # print_results_and_write_to_file(final, query, query_words, filename)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
